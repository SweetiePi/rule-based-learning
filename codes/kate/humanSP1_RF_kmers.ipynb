{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree.export import export_text\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from itertools import combinations_with_replacement\n",
    "from itertools import permutations\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file locations \n",
    "training_data = pd.read_csv('../rule-based-learning/datasets/humanSP1/humanSP1_train.csv', sep=',', header=None)\n",
    "test_data = pd.read_csv('../rule-based-learning/datasets/humanSP1/humanSP1_test.csv', sep=',', header=None)\n",
    "test_prediction = ('./humanSP1_predictions2.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get all possible kmers of length k\n",
    "def get_kmers(kmer_length): \n",
    "\n",
    "\tall_kmers = []\n",
    "\t\n",
    "\tkmers = list(combinations_with_replacement(\"ATCG\", kmer_length))\n",
    "\tfor index in range(len(kmers)):\n",
    "\t\tkmers[index] = \"\".join(kmers[index])\n",
    "\t\t\n",
    "\tfor kmer in kmers:\n",
    "\t\tpermut = list(permutations(kmer))\n",
    "\t\tpermut = list(set([\"\".join(x) for x in permut]))\n",
    "\t\tall_kmers = all_kmers + permut\n",
    "\n",
    "\treturn all_kmers\n",
    "\n",
    "#function to calculate the GC content of a list of sequences \n",
    "def calc_gc(sequences):\n",
    "    \n",
    "    gc_list = []\n",
    "    \n",
    "    for sequence in sequences:\n",
    "    \n",
    "        num_gc = 0\n",
    "        for base in sequence:\n",
    "            if base == \"G\" or base == \"C\":\n",
    "                num_gc += 1\n",
    "\n",
    "        gc_content = num_gc/len(sequence)\n",
    "        gc_list.append(gc_content)\n",
    "\n",
    "    return gc_list \n",
    "\n",
    "#function to get the list of kmer features for each sequences \n",
    "def get_features(data, kmer_list):\n",
    "\n",
    "\tfeatures = []\n",
    "\n",
    "\tseq_len = len(data[0])\n",
    "\tkmer_length = len(kmer_list[0])\n",
    "\n",
    "\tfor entry in data:\n",
    "\n",
    "\t\tfeature_count = [0] * len(kmer_list) * 2\n",
    "\t\tstart = 0\n",
    "\t\tend = kmer_length\n",
    "\n",
    "\t\twhile end <= seq_len + 1:\n",
    "\t\t\tseq_slice = entry[start:end]\n",
    "\t\t\tstart += 1\n",
    "\t\t\tend += 1\n",
    "\n",
    "\t\t\tif len(seq_slice) == kmer_length:\n",
    "\t\t\t\t#append to list of counts\n",
    "\t\t\t\tindex = kmer_list.index(seq_slice)\n",
    "\t\t\t\tfeature_count[index] += 1 \n",
    "\n",
    "\t\t#get the gc content and add this to the list of features for this sequence  \n",
    "\t\t#gc_content = calc_gc(entry)\n",
    "        \n",
    "        #feature_count.append(gc_content)\n",
    "        #append to list of all features \n",
    "\t\tfeatures.append(feature_count)\n",
    "\t\t\n",
    "\treturn features\n",
    "\n",
    "#function to get the rev. complement of a list of sequences\n",
    "def rev_comp(seqs):\n",
    "    \n",
    "    rev_seqs = []\n",
    "    \n",
    "    for seq in seqs:\n",
    "        seq = Seq(seq)\n",
    "        rev_seqs.append(seq.reverse_complement())\n",
    "        \n",
    "    return rev_seqs \n",
    "\n",
    "def combine_features(*args):\n",
    "    \n",
    "    combined_features = []\n",
    "    \n",
    "    num_features = len(args[0])\n",
    "    \n",
    "    for index in range(num_features):\n",
    "        \n",
    "        new_list = []\n",
    "        \n",
    "        for a in args:\n",
    "            if isinstance(a[index], list):\n",
    "                new_list = new_list + a[index]\n",
    "            else:\n",
    "                new_list = new_list + [a[index]]\n",
    "        \n",
    "        combined_features.append(new_list)\n",
    "        \n",
    "    return combined_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of kmers 2\n",
      "F1 score (fwd kmers only): 0.8457020729439975\n",
      "F1 score (fwd and rev kmers): 0.8601976186646612\n",
      "Number of kmers 3\n",
      "F1 score (fwd kmers only): 0.849906191369606\n",
      "F1 score (fwd and rev kmers): 0.8498722871887544\n",
      "Number of kmers 4\n",
      "F1 score (fwd kmers only): 0.8684982975226019\n",
      "F1 score (fwd and rev kmers): 0.8602802215705442\n",
      "Number of kmers 5\n",
      "F1 score (fwd kmers only): 0.8582939705473743\n",
      "F1 score (fwd and rev kmers): 0.8541261461517089\n",
      "Number of kmers 6\n",
      "F1 score (fwd kmers only): 0.8174178795814953\n",
      "F1 score (fwd and rev kmers): 0.8129392446633825\n"
     ]
    }
   ],
   "source": [
    "# training data values (X = sequences and Y = TF classification)\n",
    "X = training_data.values[:,0]\n",
    "Y = training_data.values[:, 1:2]\n",
    "\n",
    "fwd_seqs = X\n",
    "rev_seqs = rev_comp(X)\n",
    "gc_content = calc_gc(fwd_seqs)\n",
    "\n",
    "for i in range(2,15):\n",
    "    kmers = get_kmers(i)\n",
    "\n",
    "    features_fwd = get_features(fwd_seqs, kmers)\n",
    "    features_rev = get_features(rev_seqs, kmers)\n",
    "\n",
    "    all_features = combine_features(features_fwd, features_rev)\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_fwd, Y, test_size = 0.3, random_state = 100)\n",
    "\n",
    "    tfbs_classifier = RandomForestClassifier(n_estimators=100, n_jobs=12, random_state=99)\n",
    "    tfbs_classifier = tfbs_classifier.fit(X_train, np.ravel(y_train))\n",
    "    y_pred = tfbs_classifier.predict(X_test)\n",
    "    print(\"Number of kmers \" + str(i))\n",
    "    print(\"F1 score (fwd kmers only): \" + str(f1_score(y_test, y_pred, average='macro')))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(all_features, Y, test_size = 0.3, random_state = 100)\n",
    "\n",
    "    tfbs_classifier = RandomForestClassifier(n_estimators=100, n_jobs=12, random_state=99)\n",
    "    tfbs_classifier = tfbs_classifier.fit(X_train, np.ravel(y_train))\n",
    "    y_pred = tfbs_classifier.predict(X_test)\n",
    "    print(\"F1 score (fwd and rev kmers): \" + str(f1_score(y_test, y_pred, average='macro')))\n",
    "    \n",
    "    \n",
    "#features_test = get_features(test_data.values[:,0], kmers)\n",
    "#test_pred = tfbs_classifier.predict(features_test)\n",
    "\n",
    "#with open(test_prediction, \"w+\") as out:\n",
    "#\tfor entry in test_pred:\n",
    "#\t\tout.write(entry + \"\\n\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
